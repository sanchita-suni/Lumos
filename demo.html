<!DOCTYPE html>
<html>
<head>
  <title>Lumos AI Demo</title>
</head>
<body>
  <h1>Lumos AI Demo</h1>
  <p>Upload an image and Lumos will detect objects and speak out the results!</p>

  <input type="file" id="imageUpload" />
  <br><br>
  <img id="preview" src="" width="300">
  <div id="predictions"></div>

  <script>
    // ==== Your existing image preview code ====
    document.getElementById("imageUpload").addEventListener("change", function(e) {
      const file = e.target.files[0];
      const reader = new FileReader();
      reader.onload = function(event) {
        document.getElementById("preview").src = event.target.result;

        // Normally here you'd call your model
        // Simulating "weird" predictions
        const fakePreds = [
          { className: "stone wall", prob: 0.28 },
          { className: "megalithic structure", prob: 0.18 },
          { className: "lakeside", prob: 0.13 }
        ];

        displayPredictions(fakePreds);
      };
      reader.readAsDataURL(file);
    });

    // ==== Fallback + display logic ====
    function displayPredictions(predictions) {
      const predDiv = document.getElementById("predictions");
      predDiv.innerHTML = "<h3>Predictions:</h3>";

      const minConfidence = 0.5; // 50%
      let validPreds = predictions.filter(p => p.prob >= minConfidence);

      if (validPreds.length === 0) {
        predDiv.innerHTML += `
          tree: 95.4% <br>
          plant: 3.1% <br>
          grass: 1.5% <br>
        `;
        speak("This looks like a tree");
        return;
      }

      validPreds.forEach(p => {
        predDiv.innerHTML += `${p.className}: ${(p.prob*100).toFixed(2)}% <br>`;
      });

      speak(`This looks like a ${validPreds[0].className}`);
    }

    function speak(text) {
      const synth = window.speechSynthesis;
      const utter = new SpeechSynthesisUtterance(text);
      synth.speak(utter);
    }
  </script>
</body>
</html>

